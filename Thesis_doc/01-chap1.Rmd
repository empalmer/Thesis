# Chapter 1

## Introduction

Music often has subjective summary "statistics" throughout music literature and everyday conversation. For example we talk about Beethoven's Symphony 9 (think ode to joy) as "majestic, powerful, fateful, expertly written, etc", music critics go more in depth to say.... , and those with a musical background might go into more description into the actual music compared to the emotional affect. 

What if one wanted to compare Beethoven to Bach? One might say that Beethoven was a classical composer, whereas Bach was a baroque composer. What exactly to those classifiers mean? Sure, it is very well documented the years each composer was active in, and that there were large changes in the popular aspects of classical music. Even the untrained ear can distinguish differences between Bach and Beethoven. What exactly is the difference that one can hear? Does Bach follow counterpoint rules more exactly? What ways can we empirically differentiate those two composers? How about Mozart and Saliery who were contemporaries? While those familiar with classical music can spot the differences between the two composers, it is more difficult for the untrained ear or eye to spot the differences. 

What if we had a piece and didn't know who wrote it? 

## Literature Review

### Federalist Papers

Mosteller and Wallace had a similar question, but regarding writing authorship [@mosteller1964inference]. The famous Federalist Papers were written under the pen name 'Publius'. There are several disputed papers attributed to James Madison or Alexander Hamilton.  Historians have often examined the papers using styles of previously known writings of Madison and Hamilton. () Using the frequency of words such as and 'by', 'from', and 'upon' Mosteller and Wallace trained the writings on a set of pieces of each. These unconscious indicators were able to differentiate between the two writers, and when a model was trained (using .... ), the model was able to identify the author of the disputed paper.

### Music

Analyzing music, almost any piece by any composer, has already been thoroughly examined by music historians. (Paragraph about things that music historians talk about when analyzing music. find sources for this. )



The human eye, no matter how well trained in music, has an extremely hard time noticing small features throughout a piece. Even if one has a feature in mind, would one want to count the number of times an author used the word 'as' in a 500 page book? Would one trust that count to be accurate? Say one composer was very fond of middle C, and consistently used it slightly more than other composers. Unless the use of C was extreme, likely breaking rules of counterpoint and making odd melodic and harmonic choices, a human might not be able to catch this characteristic. Writing has certain rules of grammar, that one would expect all published writers to mostly follow. Writers would likely never have the word 'as' written twice in a row. Similarly, classical music has rules and conventions. Counterpoint (described in Chapter 2), melody, and characteristics of the instrument composed for constrict a composer. 

How can one find similar unconscious features comparable to word frequency for a composer?  Some  have analyzed these features in audio format (MIDI) to distinguish certain genres of music. [@de2003feature] They used self-organizing neural maps to classify music as either jazz or classical. In this paper we look at music in sheet music form. Sheet music is how composers write the music, and sheet music contains all the the information displayed clearly that a recording might not be obvious.

We then come to an interesting problem regarding extracting information from sheet music. Writing such as in the federalist papers is one word then the next, read left to right line by line, one word at a time. However music is read in a variety of ways. It can be read left to right note by note, but it can also be read vertically as the harmony, or the notes played together. Also in a piece with several instruments, the above happens at the same time for each instrument. There are also aspects that take place over large sections, such as phrasing, or cadencial patterns. There are rules of counterpoint that are followed throughout the entire piece. How then do we detect what features are those of rules and practices of classical music, and where the creativeness and individuality of a composer happens? 

Most of the musical stylometry papers have focused on composers in the Rennesaince, baroque and classical period. The Mendelssohns were composing in the Romantic period. This choice might be because composers in earlier eras had less "expressive" allowances for their composing, thus making features easier.

### Previous choices of features

Deciding on and extracting features of music is the first step to analysis. Depending on the characteristics of the composer and time period, different features would be useful. Often, features are extracted en masse and then work is done later to determine which features are important or useful in identifying style. 

There are two general groups of features. The first is low level, things such as note frequency, rhythm frequency etc. The second is high level, such as ...

Work by Backer and Kranenburg [@backer2005] (Should I talk about the data they used too?) analyzed the music of Bach, Handel, Telemann, Mozart and Haydn. Additionally they compared J.S. Bach, W.F. Bach and J.L Krebs in an attempt to classify BWV 534. They use overlapping windowing over each entire composition to produce more data, and avoid issues of dimensionality (?). They chose a window of 30 bars to create a high enough number of fragments per piece and a low enough variance of the feature values between fragments. They chose to extract 20 features. They extracted information regarding the "stability" computed by dividing the standard deviation of the lengths of the fragment by the mean length of the fragments. It is normalized in this way to be comparable over differing time signatures. They also found the fraction of the score that consisted of dissonant sororities, as well as the fraction of bars that begin with a dissonant sonority. Next they computed the entropy of the probability of occurrence of ways of thinking about chords; chords are the same no matter what scale degree they are on, and distinguishing chords differently. Next the entropy was calculated given the probability of each pitch in the score. Entropy was calculated by $-\sum_{i = 1}^{N}p_i\log{p_i}$ where $p_i$ is the probability of occurrence, and $N$ is the total number. Next they the average number of active voices at one time. This represents the voice density of the piece. Then for every interval, the duration of that interval was divided by the total duration of all intervals. Next the total duration of parallel thirds, fourths, and sixths divided by the total duration of all intervals was measured. Finally a measure of suspensions was found. 

A number of previous papers have focused on  Josquin des Prez. This is likely due to the fact that there is a large training and testing data set available in easily analyzable format provided by the Josquin Research Project (citation). In addition there are a number of pieces of disputed authorship that have been attributed to him. Work by Brinkman et al. [@brinkman2016] use machine learning approaches to evaluate attribution of compositions by des Prez. They used both high level and low level features. The high level features were 9-8 suspensions, oblique motion, contrary motion, similar motion and parallel motion. The low level features were average melodic entropy, normalized pairwise variability index (?), and note-to-note transition probabilities. 

Work by Speiser and Gupta [@CompStyleAttri] analyzed Josquin and his contemporaries to attempt to classify unknown works.  They extracted four categories of features, frequencies of individual notes, frequencies of pairwise interval combinations between each of the voices, Markov transition matrices for the rhythms of the pieces, and Markov transition matrices of the pitches in each piece. In total, this lead to a total of 3000 features. (Help why?)




### Methods for analysis

Most of the previous research has needed to do some kind of feature selection. The whole reason use machine learning is because us humans cannot detect which features are important and distinguishing. 

Backer and Krannenburg [@backer2005] used the Floating Forward Selection algorithm to extract important features. They compared each composer in their study (Bach, Handel, Telemann, Mozart and Haydn) via creating comparisons of all possible class arrangements, ie (Bach)(Handel), (Bach)(Handel,Teleman), etc. They extracted features for each class arrangement that distinguished the groups the best. For Bach and not Bach, they created a decision boundary for the features Diss Part, Par thirds, and stab time slice. For Bach and others and each individually, they classified via a k-nearest neighbor classifier. They use decision trees to interpret the features used in decision making of the different class arrangements. To determine authorship of BWV 535, they train a quadratic Bayesian classifier to distinguish J.S. Bach, W.F. Bach and J.L Krebs. They again compare every possible class arrangement as potential composers. 

Brinkman et al. [@brinkman2016] used PCa to reduce the dimensions of the features. Although only two PC's accounted for most of the variance, they decided to use 5 PC's to account for 85% of the variance. They then do binary comparisons of Josquin and other composers. This resulted in a relatively clear separation between Bach and Josquin. For Josquin and his contemporaries, the PC's do not do as well a job of separation. Using  results of the principal component analysis run on all the composers, they train a classifier on all the composers. First they use a k-nearest neighbor classifier. They use 27 PCs to again account for 85% of the variance. Next they trained a support vector machine classifier with a radial kernel. Finally they used a decision tree to determine which features were important in discerning the composers. 

Speiser and Gupta [@CompStyleAttri] scored each feature by the mutual information of each features. They then chose the top 50 features and ran GDA. They then ran PCA to attempt to remove some of the dependencies associated with musical features. They first fit a Naive Bayes for classification, but it had a large training error as the indepencence assumption does not work well with musical data. Next they used support vector machines with a gaussian kernel and GCA learning algorithms. 




## Fanny and Felix Mendelssohn









































